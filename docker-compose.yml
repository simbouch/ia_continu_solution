version: '3.8'

services:
  # FastAPI ML Application
  app:
    build: .
    container_name: fastapi_app
    ports:
      - "8000:8000"
    environment:
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    volumes:
      - app_data:/app/data
      - app_models:/app/models
      - app_logs:/app/logs
    depends_on:
      - prefect-server
    restart: unless-stopped

  # Prefect Server
  prefect-server:
    image: prefecthq/prefect:3-latest
    command: prefect server start --host 0.0.0.0
    container_name: prefect-server
    ports:
      - "4200:4200"
    volumes:
      - prefect_data:/root/.prefect
      - app_logs:/app/logs
    restart: unless-stopped

  # MLflow Server
  mlflow-server:
    image: ghcr.io/mlflow/mlflow:v2.8.1
    container_name: mlflow_server
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///tmp/mlflow/mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/tmp/mlruns
    volumes:
      - mlflow_data:/tmp/mlflow
      - mlflow_data:/tmp/mlruns
    command: >
      mlflow server
      --backend-store-uri sqlite:///tmp/mlflow/mlflow.db
      --default-artifact-root /tmp/mlruns
      --host 0.0.0.0
      --port 5000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5000', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s

  # Random Check Flow
  random-check-flow:
    build: .
    container_name: random_check_flow
    depends_on:
      - prefect-server
      - app
    environment:
      - PREFECT_API_URL=http://prefect-server:4200/api
      - PYTHONIOENCODING=utf-8
      - API_URL=http://fastapi_app:8000
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
    volumes:
      - app_logs:/app/logs
    command: python flow.py
    restart: unless-stopped

  # Uptime Kuma
  uptime-kuma:
    image: louislam/uptime-kuma:latest
    container_name: uptime_kuma
    ports:
      - "3001:3001"
    volumes:
      - uptime-kuma-data:/app/data
    restart: unless-stopped

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: unless-stopped

  # Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana-dashboard.json:/etc/grafana/provisioning/dashboards/dashboard.json
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    restart: unless-stopped

  # Streamlit UI
  streamlit-ui:
    build: .
    container_name: streamlit_ui
    ports:
      - "8501:8501"
    environment:
      - API_URL=http://fastapi_app:8000
    volumes:
      - app_logs:/app/logs
    command: streamlit run streamlit_app.py --server.port=8501 --server.address=0.0.0.0
    depends_on:
      - app
    restart: unless-stopped

volumes:
  app_data:
  app_models:
  app_logs:
  prefect_data:
  uptime-kuma-data:
  mlflow_data:
  prometheus_data:
  grafana_data: