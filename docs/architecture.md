# Architecture IA Continu Solution üèóÔ∏è

## Vue d'ensemble

L'IA Continu Solution est une plateforme compl√®te de Machine Learning en production qui impl√©mente un pipeline automatis√© de d√©tection de d√©rive de mod√®le avec r√©entra√Ænement intelligent, monitoring temps r√©el, et notifications automatiques.

## üéØ Principes Architecturaux

- **Microservices** : Services d√©coupl√©s et ind√©pendants
- **Containerisation** : D√©ploiement Docker pour la portabilit√©
- **Monitoring** : Observabilit√© compl√®te du syst√®me
- **Automatisation** : Workflows orchestr√©s avec Prefect
- **Scalabilit√©** : Architecture pr√™te pour la mont√©e en charge

## üèóÔ∏è Architecture Globale

```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[Streamlit UI<br/>Port 8501]
        API[FastAPI<br/>Port 8000]
    end
    
    subgraph "ML Layer"
        MLF[MLflow Server<br/>Port 5000]
        MODEL[Model Storage<br/>models/]
    end
    
    subgraph "Orchestration Layer"
        PREFECT[Prefect Server<br/>Port 4200]
        FLOW[Random Check Flow<br/>30s intervals]
    end
    
    subgraph "Monitoring Layer"
        UPTIME[Uptime Kuma<br/>Port 3001]
        PROM[Prometheus<br/>Port 9090]
        GRAF[Grafana<br/>Port 3000]
    end
    
    subgraph "Data Layer"
        DB[(SQLite Database<br/>data/)]
        LOGS[Logs<br/>logs/]
    end
    
    subgraph "External"
        DISCORD[Discord Webhooks]
        GITHUB[GitHub Actions]
    end
    
    UI --> API
    API --> DB
    API --> MODEL
    API --> MLF
    FLOW --> API
    PREFECT --> FLOW
    UPTIME --> API
    PROM --> API
    GRAF --> PROM
    API --> DISCORD
    GITHUB --> API
```

## üîß Composants D√©taill√©s

### 1. API Layer (FastAPI)

**Localisation** : `src/api/main.py`  
**Port** : 8000  
**Responsabilit√©s** :
- Exposition des endpoints REST
- Gestion des pr√©dictions ML
- Orchestration du r√©entra√Ænement
- Int√©gration MLflow
- Notifications Discord

**Endpoints** :
```python
GET  /health      # Health check
POST /predict     # ML predictions
POST /retrain     # Model retraining
POST /generate    # Dataset generation
```

### 2. Database Layer (SQLite + SQLAlchemy)

**Localisation** : `src/database/db_manager.py`  
**Fichier** : `data/ia_continu_solution.db`  
**Tables** :

```sql
-- Datasets g√©n√©r√©s
CREATE TABLE datasets (
    generation_id INTEGER PRIMARY KEY,
    samples_count INTEGER,
    hour_generated INTEGER,
    created_at TIMESTAMP
);

-- √âchantillons de donn√©es
CREATE TABLE dataset_samples (
    id INTEGER PRIMARY KEY,
    generation_id INTEGER,
    feature1 REAL,
    feature2 REAL,
    target INTEGER,
    FOREIGN KEY (generation_id) REFERENCES datasets
);

-- Mod√®les entra√Æn√©s
CREATE TABLE models (
    id INTEGER PRIMARY KEY,
    version TEXT UNIQUE,
    accuracy REAL,
    training_samples INTEGER,
    created_at TIMESTAMP,
    is_active BOOLEAN
);
```

### 3. ML Layer (MLflow + Scikit-learn)

**Localisation** : `src/mlflow_service/mlflow_manager.py`  
**Port MLflow** : 5000  
**Responsabilit√©s** :
- Tracking des exp√©riences ML
- Versioning des mod√®les
- M√©triques de performance
- Artifacts storage

**Workflow ML** :
```python
1. G√©n√©ration dataset ‚Üí Donn√©es synth√©tiques
2. Entra√Ænement ‚Üí LogisticRegression
3. √âvaluation ‚Üí Accuracy, m√©triques
4. Logging MLflow ‚Üí Tracking exp√©rience
5. Sauvegarde ‚Üí Mod√®le + m√©tadonn√©es
6. Activation ‚Üí Mod√®le en production
```

### 4. Orchestration Layer (Prefect)

**Localisation** : `flow.py`  
**Port Prefect** : 4200  
**Fr√©quence** : 30 secondes  

**Pipeline Automatique** :
```python
@flow
def periodic_check():
    1. Health check API
    2. G√©n√©ration nombre al√©atoire
    3. Si < 0.5 ‚Üí D√©rive d√©tect√©e
    4. D√©clenchement r√©entra√Ænement
    5. Notification Discord
```

### 5. Monitoring Layer

#### Uptime Kuma
**Port** : 3001  
**Fonction** : Surveillance disponibilit√©  
**Monitors** :
- API /health endpoint
- Services Docker
- Temps de r√©ponse

#### Prometheus
**Port** : 9090  
**Fonction** : Collecte m√©triques  
**M√©triques** :
- API requests/responses
- System resources (CPU, RAM)
- ML metrics (accuracy, predictions)

#### Grafana
**Port** : 3000  
**Fonction** : Visualisation  
**Dashboards** :
- API Performance
- System Health
- ML Metrics
- Business KPIs

### 6. Configuration Layer

**Localisation** : `config/settings.py`  
**Responsabilit√©s** :
- Configuration centralis√©e
- Variables d'environnement
- Param√®tres par d√©faut

```python
# Configuration principale
API_HOST = "0.0.0.0"
API_PORT = 8000
MLFLOW_TRACKING_URI = "http://localhost:5000"
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")
MONITORING_INTERVAL = 30  # seconds
```

## üê≥ Containerisation Docker

### Services Docker Compose

```yaml
services:
  # Application principale
  app:
    build: .
    ports: ["8000:8000"]
    volumes: [data, models, logs]
    
  # Orchestration
  prefect-server:
    image: prefecthq/prefect:3-latest
    ports: ["4200:4200"]
    
  # ML Tracking
  mlflow-server:
    image: python:3.11-slim
    ports: ["5000:5000"]
    
  # Monitoring
  uptime-kuma:
    image: louislam/uptime-kuma
    ports: ["3001:3001"]
    
  # Pipeline
  random-check-flow:
    build: .
    command: python flow.py
```

### Volumes Persistants
- `app_data` : Base de donn√©es SQLite
- `app_models` : Mod√®les ML sauvegard√©s
- `app_logs` : Fichiers de logs
- `mlflow_data` : Artifacts MLflow

## üîÑ Flux de Donn√©es

### 1. Flux de Pr√©diction
```
Client ‚Üí FastAPI ‚Üí Model ‚Üí Prediction ‚Üí Response
                ‚Üì
            Log ‚Üí Database
```

### 2. Flux de R√©entra√Ænement
```
Prefect Flow ‚Üí Random Check ‚Üí API /retrain
                                ‚Üì
            Generate Data ‚Üí Train Model ‚Üí MLflow
                                ‚Üì
            Save Model ‚Üí Update Database ‚Üí Discord
```

### 3. Flux de Monitoring
```
Services ‚Üí Prometheus ‚Üí Grafana ‚Üí Dashboards
    ‚Üì
Uptime Kuma ‚Üí Health Checks ‚Üí Alerts
```

## üîê S√©curit√©

### Authentification
- **JWT Tokens** : Authentification API
- **Environment Variables** : Secrets management
- **Docker Networks** : Isolation services

### Logging & Audit
- **Structured Logs** : Format JSON
- **Log Rotation** : Gestion espace disque
- **Audit Trail** : Tra√ßabilit√© actions

## üìä M√©triques et KPIs

### Performance API
- Latence moyenne : < 100ms
- Throughput : 1000 req/min
- Disponibilit√© : 99.9%
- Taux d'erreur : < 0.1%

### ML Metrics
- Model accuracy : > 90%
- Training time : < 30s
- Prediction confidence : > 80%
- Drift detection : Real-time

### System Metrics
- CPU utilisation : < 70%
- Memory usage : < 80%
- Disk space : Monitored
- Network I/O : Tracked

## üöÄ D√©ploiement

### Environnements
- **Development** : Local Docker
- **Staging** : Docker Compose
- **Production** : Kubernetes (future)

### CI/CD Pipeline
```
GitHub Push ‚Üí Actions ‚Üí Tests ‚Üí Build ‚Üí Deploy
                ‚Üì
            Quality Gates ‚Üí Security Scan ‚Üí Release
```

### Rollback Strategy
- **Blue/Green** : D√©ploiement sans interruption
- **Database Migrations** : Alembic versioning
- **Model Rollback** : Version pr√©c√©dente

## üîÆ √âvolutions Futures

### Scalabilit√©
- **Kubernetes** : Orchestration cloud
- **Redis** : Cache distribu√©
- **PostgreSQL** : Base de donn√©es scalable

### ML Avanc√©
- **Deep Learning** : Mod√®les complexes
- **AutoML** : Optimisation automatique
- **Feature Store** : Gestion features

### Monitoring Avanc√©
- **Distributed Tracing** : Jaeger/Zipkin
- **APM** : Application Performance Monitoring
- **Alerting** : PagerDuty integration

---

**Version Architecture** : 2.0.0  
**Derni√®re mise √† jour** : Jour 3  
**Statut** : Production Ready üöÄ
