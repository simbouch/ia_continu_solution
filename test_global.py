#!/usr/bin/env python3
"""
Global Test Suite for IA Continu Solution
Single comprehensive test file to validate all functionality
"""

import requests
import time
import os
import json
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configuration
API_BASE_URL = "http://localhost:8000"
PREFECT_URL = "http://localhost:4200"
UPTIME_KUMA_URL = "http://localhost:3001"
MLFLOW_URL = "http://localhost:5000"
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")

def send_discord_embed(message, status="Succ√®s"):
    """Send message to Discord via Webhook according to specifications"""
    if not DISCORD_WEBHOOK_URL:
        print("Discord webhook not configured")
        return False
    
    color = 5814783 if status == "Succ√®s" else 15158332  # Green or Red
    
    data = {
        "embeds": [{
            "title": "R√©sultats du pipeline",
            "description": message,
            "color": color,
            "fields": [{
                "name": "Status",
                "value": status,
                "inline": True
            }]
        }]
    }
    
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=data, timeout=10)
        if response.status_code != 204:
            print(f"Erreur lors de l'envoi de l'embed : {response.status_code}")
            return False
        else:
            print("Embed envoy√© avec succ√®s !")
            return True
    except Exception as e:
        print(f"Erreur Discord: {e}")
        return False

def test_api_health():
    """Test API health endpoint - should return 200"""
    print("üè• Testing API Health...")
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=10)
        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        
        data = response.json()
        assert "status" in data, "Response should contain 'status'"
        assert data["status"] == "ok", "Status should be 'ok'"
        
        print("   ‚úÖ Health endpoint returns 200 and correct format")
        return True
    except Exception as e:
        print(f"   ‚ùå Health test failed: {e}")
        return False

def test_api_predict():
    """Test predict endpoint - should return 0 or 1"""
    print("üéØ Testing API Predict...")
    try:
        payload = {"features": [0.5, -0.3]}
        response = requests.post(f"{API_BASE_URL}/predict", json=payload, timeout=10)
        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        
        data = response.json()
        assert "prediction" in data, "Response should contain 'prediction'"
        assert data["prediction"] in [0, 1], f"Prediction should be 0 or 1, got {data['prediction']}"
        assert "confidence" in data, "Response should contain 'confidence'"
        assert 0 <= data["confidence"] <= 1, "Confidence should be between 0 and 1"
        
        print(f"   ‚úÖ Predict returns {data['prediction']} with confidence {data['confidence']:.3f}")
        return True
    except Exception as e:
        print(f"   ‚ùå Predict test failed: {e}")
        return False

def test_api_generate():
    """Test generate endpoint and database storage"""
    print("üìä Testing API Generate and Database...")
    try:
        payload = {"samples": 150}
        response = requests.post(f"{API_BASE_URL}/generate", json=payload, timeout=15)
        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        
        data = response.json()
        assert "generation_id" in data, "Response should contain 'generation_id'"
        assert "samples_created" in data, "Response should contain 'samples_created'"
        assert data["samples_created"] == 150, f"Expected 150 samples, got {data['samples_created']}"
        
        generation_id = data["generation_id"]
        
        # Test database by checking datasets list
        time.sleep(1)  # Wait for database write
        datasets_response = requests.get(f"{API_BASE_URL}/datasets/list", timeout=10)
        assert datasets_response.status_code == 200, "Datasets list should be accessible"
        
        datasets_data = datasets_response.json()
        assert "datasets" in datasets_data, "Response should contain 'datasets'"
        assert "total_datasets" in datasets_data, "Response should contain 'total_datasets'"
        
        # Check if our generated dataset is in the list
        found_dataset = any(d["generation_id"] == generation_id for d in datasets_data["datasets"])
        assert found_dataset, "Generated dataset should be found in database"
        
        print(f"   ‚úÖ Generated dataset {generation_id} with 150 samples and stored in database")
        return True
    except Exception as e:
        print(f"   ‚ùå Generate/Database test failed: {e}")
        return False

def test_api_retrain():
    """Test retrain endpoint with MLflow integration"""
    print("üîÑ Testing API Retrain with MLflow...")
    try:
        # First ensure we have data
        gen_response = requests.post(f"{API_BASE_URL}/generate", json={"samples": 200}, timeout=15)
        assert gen_response.status_code == 200, "Should generate data first"
        
        time.sleep(2)  # Wait for database write
        
        # Test retrain
        response = requests.post(f"{API_BASE_URL}/retrain", timeout=60)
        assert response.status_code == 200, f"Expected 200, got {response.status_code}"
        
        data = response.json()
        assert "status" in data, "Response should contain 'status'"
        assert data["status"] == "success", "Retrain should be successful"
        assert "model_version" in data, "Response should contain 'model_version'"
        assert "accuracy" in data, "Response should contain 'accuracy'"
        assert "training_samples" in data, "Response should contain 'training_samples'"
        
        assert 0 <= data["accuracy"] <= 1, "Accuracy should be between 0 and 1"
        assert data["training_samples"] > 0, "Should have training samples"
        
        print(f"   ‚úÖ Retrain successful: {data['model_version']}, accuracy: {data['accuracy']:.3f}")
        return True
    except Exception as e:
        print(f"   ‚ùå Retrain test failed: {e}")
        return False

def test_prefect_service():
    """Test Prefect server"""
    print("‚ö° Testing Prefect Service...")
    try:
        # Test health endpoint
        health_response = requests.get(f"{PREFECT_URL}/api/health", timeout=10)
        assert health_response.status_code == 200, "Prefect health should return 200"
        
        # Test UI
        ui_response = requests.get(f"{PREFECT_URL}", timeout=10)
        assert ui_response.status_code == 200, "Prefect UI should be accessible"
        
        print("   ‚úÖ Prefect server and UI accessible")
        return True
    except Exception as e:
        print(f"   ‚ùå Prefect test failed: {e}")
        return False

def test_uptime_kuma():
    """Test Uptime Kuma service"""
    print("üìä Testing Uptime Kuma...")
    try:
        response = requests.get(f"{UPTIME_KUMA_URL}", timeout=10)
        assert response.status_code == 200, "Uptime Kuma should return 200"
        
        print("   ‚úÖ Uptime Kuma accessible on port 3001")
        return True
    except Exception as e:
        print(f"   ‚ùå Uptime Kuma test failed: {e}")
        return False

def test_mlflow_service():
    """Test MLflow service"""
    print("üî¨ Testing MLflow Service...")
    try:
        response = requests.get(f"{MLFLOW_URL}", timeout=10)
        if response.status_code == 200:
            print("   ‚úÖ MLflow UI accessible")
            return True
        else:
            print(f"   ‚ö†Ô∏è MLflow not accessible (status: {response.status_code})")
            return False
    except Exception as e:
        print(f"   ‚ö†Ô∏è MLflow not accessible: {e}")
        return False

def test_discord_integration():
    """Test Discord webhook integration"""
    print("üì± Testing Discord Integration...")
    
    if not DISCORD_WEBHOOK_URL:
        print("   ‚ö†Ô∏è Discord webhook not configured")
        return False
    
    # Test success notification
    success = send_discord_embed("Test global du syst√®me IA Continu - Tous les tests pass√©s!", "Succ√®s")
    
    if success:
        print("   ‚úÖ Discord webhook working")
        return True
    else:
        print("   ‚ùå Discord webhook failed")
        return False

def test_complete_workflow():
    """Test complete ML workflow"""
    print("ü§ñ Testing Complete ML Workflow...")
    try:
        # Step 1: Generate dataset
        print("   1. Generating dataset...")
        gen_response = requests.post(f"{API_BASE_URL}/generate", json={"samples": 300}, timeout=20)
        assert gen_response.status_code == 200, "Dataset generation should succeed"
        gen_data = gen_response.json()
        
        # Step 2: Make prediction
        print("   2. Making prediction...")
        pred_response = requests.post(f"{API_BASE_URL}/predict", json={"features": [0.7, -0.4]}, timeout=10)
        assert pred_response.status_code == 200, "Prediction should succeed"
        pred_data = pred_response.json()
        
        # Step 3: Retrain model
        print("   3. Retraining model...")
        time.sleep(2)  # Wait for database
        retrain_response = requests.post(f"{API_BASE_URL}/retrain", timeout=60)
        assert retrain_response.status_code == 200, "Retrain should succeed"
        retrain_data = retrain_response.json()
        
        # Step 4: Make prediction with new model
        print("   4. Testing new model...")
        time.sleep(1)  # Wait for model to be updated in memory
        pred2_response = requests.post(f"{API_BASE_URL}/predict", json={"features": [0.7, -0.4]}, timeout=10)
        assert pred2_response.status_code == 200, "New prediction should succeed"
        pred2_data = pred2_response.json()

        # Verify workflow
        assert retrain_data["training_samples"] == 300, "Should train on 300 samples"

        # Check if model version was updated
        if pred2_data["model_version"] != retrain_data["model_version"]:
            print(f"   ‚ö†Ô∏è Model version mismatch: expected {retrain_data['model_version']}, got {pred2_data['model_version']}")
            # This might be a timing issue, let's check model info endpoint
            model_info_response = requests.get(f"{API_BASE_URL}/model/info", timeout=10)
            if model_info_response.status_code == 200:
                model_info = model_info_response.json()
                print(f"   üìä Current model info: {model_info['model_version']}")
                if model_info["model_version"] == retrain_data["model_version"]:
                    print("   ‚úÖ Model was updated correctly (timing issue in prediction)")
                else:
                    raise AssertionError(f"Model version not updated: expected {retrain_data['model_version']}, got {model_info['model_version']}")
            else:
                raise AssertionError("Could not verify model info")
        else:
            print(f"   ‚úÖ Model version updated correctly: {pred2_data['model_version']}")
        
        print(f"   ‚úÖ Complete workflow: Generated {gen_data['samples_created']} samples, "
              f"retrained model {retrain_data['model_version']} with {retrain_data['accuracy']:.3f} accuracy")
        return True
    except Exception as e:
        print(f"   ‚ùå Complete workflow failed: {e}")
        return False

def main():
    """Run all global tests"""
    print("üéØ IA CONTINU SOLUTION - GLOBAL TEST SUITE")
    print("=" * 50)
    print()
    
    # Wait for services to be ready
    print("‚è≥ Waiting for services to be ready...")
    time.sleep(5)
    
    # Run all tests
    tests = [
        ("API Health", test_api_health),
        ("API Predict", test_api_predict),
        ("API Generate & Database", test_api_generate),
        ("API Retrain & MLflow", test_api_retrain),
        ("Prefect Service", test_prefect_service),
        ("Uptime Kuma", test_uptime_kuma),
        ("MLflow Service", test_mlflow_service),
        ("Discord Integration", test_discord_integration),
        ("Complete ML Workflow", test_complete_workflow)
    ]
    
    results = {}
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{'='*20}")
        try:
            result = test_func()
            results[test_name] = result
            if result:
                passed += 1
        except Exception as e:
            print(f"‚ùå {test_name} failed with exception: {e}")
            results[test_name] = False
    
    # Final summary
    print(f"\n{'='*50}")
    print("üéØ GLOBAL TEST RESULTS")
    print("=" * 50)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status} {test_name}")
    
    success_rate = (passed / total) * 100
    print(f"\nüìä Overall Result: {passed}/{total} tests passed ({success_rate:.1f}%)")
    
    if success_rate >= 80:
        print("\nüéâ SYSTEM VALIDATION SUCCESSFUL!")
        print("‚úÖ IA Continu Solution is production ready!")
        
        # Send success notification
        if DISCORD_WEBHOOK_URL:
            send_discord_embed(f"Validation globale termin√©e avec succ√®s! {passed}/{total} tests pass√©s ({success_rate:.1f}%)")
    else:
        print(f"\n‚ö†Ô∏è System needs attention ({total - passed} failures)")
        
        # Send failure notification
        if DISCORD_WEBHOOK_URL:
            send_discord_embed(f"Validation globale √©chou√©e. {passed}/{total} tests pass√©s ({success_rate:.1f}%)", "√âchec")
    
    print(f"\nüåê Service URLs:")
    print(f"   ‚Ä¢ API: {API_BASE_URL}")
    print(f"   ‚Ä¢ API Docs: {API_BASE_URL}/docs")
    print(f"   ‚Ä¢ Prefect: {PREFECT_URL}")
    print(f"   ‚Ä¢ Uptime Kuma: {UPTIME_KUMA_URL}")
    print(f"   ‚Ä¢ MLflow: {MLFLOW_URL}")

if __name__ == "__main__":
    main()
