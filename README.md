# IA Continu Solution ðŸ¤–

## ðŸŽ¯ Objectif

Solution complÃ¨te de Machine Learning en continu avec monitoring, API REST, et pipeline automatisÃ©. Ce projet implÃ©mente un systÃ¨me intelligent de dÃ©tection de dÃ©rive de modÃ¨le avec rÃ©entraÃ®nement automatique, monitoring en temps rÃ©el, et notifications Discord.

## ðŸ—ï¸ Architecture

```
ia_continu_solution/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                 # API FastAPI
â”‚   â”‚   â””â”€â”€ main.py         # Endpoints REST
â”‚   â”œâ”€â”€ database/           # Gestion base de donnÃ©es
â”‚   â”‚   â””â”€â”€ db_manager.py   # SQLite + ORM
â”‚   â”œâ”€â”€ mlflow_service/     # MLflow integration
â”‚   â”‚   â””â”€â”€ mlflow_manager.py
â”‚   â”œâ”€â”€ monitoring/         # Monitoring & notifications
â”‚   â”‚   â””â”€â”€ discord_notifier.py
â”‚   â””â”€â”€ utils/              # Utilitaires
â”œâ”€â”€ config/                 # Configuration centralisÃ©e
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ tests/                  # Tests unitaires
â”œâ”€â”€ data/                   # Base de donnÃ©es SQLite
â”œâ”€â”€ models/                 # ModÃ¨les ML sauvegardÃ©s
â”œâ”€â”€ logs/                   # Fichiers de logs
â”œâ”€â”€ docker-compose.yml      # Orchestration services
â””â”€â”€ flow.py                 # Pipeline Prefect
```

## ðŸš€ Services DÃ©ployÃ©s

- **FastAPI** (Port 8000) : API REST pour ML
- **Prefect Server** (Port 4200) : Orchestration workflows
- **Uptime Kuma** (Port 3001) : Monitoring uptime
- **MLflow** (Port 5000) : Tracking expÃ©riences ML
- **Pipeline Prefect** : VÃ©rifications toutes les 30s

## ðŸ“¡ Endpoints API

### ðŸ” Health Check
```http
GET /health
```
VÃ©rification de l'Ã©tat de l'API.

**RÃ©ponse :**
```json
{
  "status": "ok",
  "timestamp": "2024-01-01T12:00:00Z",
  "version": "2.0.0"
}
```

### ðŸŽ¯ PrÃ©diction
```http
POST /predict
```
Effectue une prÃ©diction avec le modÃ¨le actuel.

**Body :**
```json
{
  "features": [1.5, 2.3]
}
```

**RÃ©ponse :**
```json
{
  "prediction": 1,
  "model_version": "v1.0.0",
  "confidence": 0.85,
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### ðŸ”„ RÃ©entraÃ®nement
```http
POST /retrain
```
Lance le rÃ©entraÃ®nement du modÃ¨le avec nouvelles donnÃ©es.

**RÃ©ponse :**
```json
{
  "status": "success",
  "model_version": "v1.1.0",
  "training_samples": 1000,
  "accuracy": 0.92,
  "timestamp": "2024-01-01T12:00:00Z"
}
```

### ðŸ“Š GÃ©nÃ©ration de donnÃ©es
```http
POST /generate
```
GÃ©nÃ¨re un nouveau dataset pour l'entraÃ®nement.

**Body :**
```json
{
  "samples": 1000
}
```

## ðŸ³ Lancement avec Docker

### PrÃ©requis
- Docker & Docker Compose
- Variable d'environnement `DISCORD_WEBHOOK_URL`

### DÃ©marrage rapide
```bash
# Cloner le repository
git clone https://github.com/simbouch/ia_continu_solution.git
cd ia_continu_solution

# Configurer Discord webhook
echo "DISCORD_WEBHOOK_URL=your_webhook_url" > .env

# Lancer tous les services
docker-compose up -d

# VÃ©rifier les services
docker-compose ps
```

### AccÃ¨s aux services
- **API** : http://localhost:8000
- **Prefect UI** : http://localhost:4200
- **Uptime Kuma** : http://localhost:3001
- **MLflow** : http://localhost:5000

## ðŸ§ª Tests

```bash
# Tests unitaires
python -m pytest tests/ -v

# Test complet du systÃ¨me
python test_global.py

# Test API spÃ©cifique
python tests/test_api.py
```

## ðŸ“Š Monitoring

### Pipeline Automatique
- **FrÃ©quence** : Toutes les 30 secondes
- **Logique** : GÃ©nÃ¨re nombre alÃ©atoire
- **Seuil** : Si < 0.5 â†’ RÃ©entraÃ®nement automatique
- **Notifications** : Discord embeds

### Uptime Kuma
- Surveillance continue de l'API
- Alertes en cas de panne
- Dashboard de disponibilitÃ©

## ðŸ”§ Configuration

### Variables d'environnement
```bash
# Discord
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...

# API
API_HOST=0.0.0.0
API_PORT=9000

# MLflow
MLFLOW_TRACKING_URI=http://localhost:5000

# Logging
LOG_LEVEL=INFO
```

### Base de donnÃ©es
- **Type** : SQLite
- **Localisation** : `data/ia_continu_solution.db`
- **Tables** : datasets, dataset_samples, models

## ðŸ”„ Workflow ML

1. **GÃ©nÃ©ration de donnÃ©es** â†’ Dataset synthÃ©tique
2. **EntraÃ®nement** â†’ ModÃ¨le LogisticRegression
3. **Ã‰valuation** â†’ MÃ©triques de performance
4. **Logging MLflow** â†’ Tracking expÃ©riences
5. **Sauvegarde** â†’ ModÃ¨le + mÃ©tadonnÃ©es
6. **Monitoring** â†’ Surveillance continue
7. **RÃ©entraÃ®nement** â†’ Si dÃ©rive dÃ©tectÃ©e

## ðŸ“ˆ MÃ©triques Suivies

- **Accuracy** : PrÃ©cision du modÃ¨le
- **Training samples** : Nombre d'Ã©chantillons
- **Model version** : Versioning automatique
- **Response time** : Temps de rÃ©ponse API
- **Uptime** : DisponibilitÃ© services

## ðŸš¨ Notifications Discord

Format des notifications :
```json
{
  "title": "RÃ©sultats du pipeline",
  "description": "Message dÃ©taillÃ©",
  "fields": [{
    "name": "Status",
    "value": "SuccÃ¨s" | "Ã‰chec"
  }]
}
```

## ðŸ› ï¸ DÃ©veloppement

### Structure du code
- **FastAPI** : API REST moderne
- **SQLAlchemy** : ORM pour base de donnÃ©es
- **Prefect** : Orchestration workflows
- **MLflow** : Tracking ML
- **Docker** : Containerisation
- **Pytest** : Tests automatisÃ©s

### Ajout de nouvelles fonctionnalitÃ©s
1. Modifier `src/api/main.py` pour nouveaux endpoints
2. Mettre Ã  jour `src/database/db_manager.py` pour nouveaux modÃ¨les
3. Ajouter tests dans `tests/`
4. Documenter dans `docs/`

## ðŸ“š Documentation

- `docs/jour1-summary.md` : RÃ©sumÃ© Jour 1
- `docs/jour2-summary.md` : RÃ©sumÃ© Jour 2
- `docs/jour3-summary.md` : RÃ©sumÃ© Jour 3

## ðŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature
3. Commit les changements
4. Push vers la branche
5. Ouvrir une Pull Request

## ðŸ“„ Licence

MIT License - voir fichier LICENSE

---

**Version** : 2.0.0  
**DerniÃ¨re mise Ã  jour** : Jour 3  
**Statut** : Production Ready ðŸš€
