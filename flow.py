import os
import random
import requests
from prefect import flow, task
from prefect.logging import get_run_logger
from datetime import datetime

from utilities import send_discord_embed
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score
import joblib
import mlflow
from mlflow.exceptions import MlflowException

# Set environment variables for Prefect
# PYTHONIOENCODING: √©vite les UnicodeDecodeError sous Windows
# PREFECT_API_URL: indique au SDK o√π se trouve l'API Prefect
os.environ.setdefault("PYTHONIOENCODING", "utf-8")
os.environ.setdefault("PREFECT_API_URL", "http://127.0.0.1:4200/api")


@task
def check_accuracy():
    logger = get_run_logger()

    # Charger le mod√®le sauvegard√©
    try:
        model = joblib.load("model.pkl")
    except FileNotFoundError:
        logger.warning("Aucun mod√®le local trouv√©.")
        send_discord_embed(f"üö® Aucun mod√®le local trouv√©. - Training n√©cessaire")
        
        return {"status": "no_model"}

    data = get_last_dataset()
    if not data:
        logger.warning("Pas de donn√©es disponibles.")
        send_discord_embed(f"üö® Pas de donn√©es disponibles. - Impossible d'entrainer")
        
        return {"status": "no_data"}

    X = [[row.feature1, row.feature2] for row in data]
    Y = [row.target for row in data]

    if not X or not Y:
        return {"status": "no_data"}

    # Pr√©diction et accuracy
    Y_pred = model.predict(X)
    current_accuracy = accuracy_score(Y, Y_pred)

    # Lire derni√®re accuracy de MLflow
    client = mlflow.tracking.MlflowClient()
    runs = client.search_runs(experiment_ids=["0"], order_by=["start_time DESC"], max_results=1)

    if not runs or "accuracy" not in runs[0].data.metrics:
        logger.warning("Pas d'ancienne m√©trique d'accuracy trouv√©e.")
        send_discord_embed(f"üö® Pas d'ancienne m√©trique d'accuracy trouv√©e. - Training n√©cessaire")
        return {"status": "no_previous_accuracy"}

    previous_accuracy = runs[0].data.metrics["accuracy"]

    logger.info(f"Accuracy actuelle: {current_accuracy:.3f} ‚Äî Pr√©c√©dente: {previous_accuracy:.3f}")

    if current_accuracy < previous_accuracy:
        logger.warning(f"D√©rive d√©tect√©e ! Accuracy {accuracy:.3f} < derni√®re accuracy {last_accuracy} - seuil {threshold}")
        send_discord_embed(f"üö® D√©rive du mod√®le d√©tect√©e! Accuracy actuelle: {accuracy:.3f}, derni√®re accuracy: {last_accuracy} - Retraining n√©cessaire")
        return {"status": "drift", "accuracy": current_accuracy}
    else:
        logger.info(f"Mod√®le OK ! Accuracy {accuracy:.3f} >= derni√®re accuracy {last_accuracy} - seuil {threshold}")
        send_discord_embed(f"‚úÖ Mod√®le performant! Accuracy: {accuracy:.3f}")
        return {"status": "ok", "accuracy": current_accuracy}
    


@task(retries=2, retry_delay_seconds=1)
def check_random():
    """
    G√©n√®re un nombre al√©atoire et d√©clenche un retrain si < 0.5
    Le tirage al√©atoire joue le r√¥le d'un test de performance :
    un r√©sultat < 0.5 symbolise la d√©rive d'un mod√®le qu'il faut r√©-entra√Æner.
    """
    logger = get_run_logger()

    # G√©n√©rer un nombre al√©atoire entre 0 et 1
    random_value = random.random()
    logger.info(f"Valeur al√©atoire g√©n√©r√©e: {random_value:.3f}")

    if random_value < 0.5:
        # Symbolise la d√©rive du mod√®le - d√©clenche un √©chec + retries
        logger.warning(f"D√©rive d√©tect√©e! Valeur: {random_value:.3f} < 0.5")
        send_discord_embed(f"üö® D√©rive du mod√®le d√©tect√©e! Valeur: {random_value:.3f} - Retraining n√©cessaire")
        raise ValueError(f"Model drift detected: {random_value:.3f} < 0.5 - Initiating retrain")
    else:
        # Mod√®le OK
        logger.info(f"Mod√®le OK! Valeur: {random_value:.3f} >= 0.5")
        send_discord_embed(f"‚úÖ Mod√®le performant! Valeur: {random_value:.3f}")
        return {"status": "ok", "value": random_value}




def save_last_model_mlflow_to_joblib():
    model = mlflow.sklearn.load_model("models:/my_model/latest")
    joblib.dump(model, "model.pkl")


@task
def train_model():
    model=LinearRegression()
    data=get_last_dataset(db)
    X=[[X.feature1,X.feature2] for X in data]
    Y=[X.target for X in data]
    with mlflow.start_run():
        model.fit(X,Y)
        Y_pred=model.predict(X)
        accuracy=accuracy_score(Y,Y_pred)
        mlflow.sklearn.log_model(model, "model")
        mlflow.log_metrics({"accuracy": accuracy})

    message = f"üìà Nouveau mod√®le entra√Æn√© ‚Äî Accuracy : {accuracy:.3f}"
    logger.info(message)
    send_discord_embed(message, "Succ√®s")
    
    save_last_model_mlflow_to_joblib()

@flow
def periodic_check():
    logger = get_run_logger()
    logger.info("üí° Lancement de la v√©rification p√©riodique...")

    check_future = check_accuracy.submit()
    result = check_future.result()  # attend le r√©sultat

    if result["status"] in {"no_model", "no_previous_accuracy", "drift"}:
        logger.warning(f"‚ö†Ô∏è Entra√Ænement n√©cessaire : {result['status']}")
        train_model.submit()
    elif result["status"] == "ok":
        logger.info(f"‚úÖ Mod√®le performant (accuracy: {result['accuracy']:.3f})")
    else:
        logger.warning(f"‚ùå √âtat inattendu ou donn√©es manquantes : {result['status']}")


if __name__ == "__main__":
    # Planifier l'ex√©cution toutes les 30 secondes
    # Le bloc if __name__ == "__main__": sert √† lancer le scheduler et le worker int√©gr√©s
    # lorsque vous ex√©cutez directement le fichier ; il est ignor√© si le module est import√© ailleurs.
    periodic_check.serve(
        name="random-check-every-30s",
        interval=30,
        description="Pipeline random-check qui s'ex√©cute toutes les 30 secondes"
    )
