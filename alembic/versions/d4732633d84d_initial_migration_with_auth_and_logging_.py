"""Initial migration with auth and logging tables

Revision ID: d4732633d84d
Revises: 
Create Date: 2025-06-18 11:00:13.108863

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'd4732633d84d'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('drift_detections',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('model_version', sa.String(length=100), nullable=False),
    sa.Column('detection_method', sa.String(length=50), nullable=False),
    sa.Column('trigger_value', sa.Float(), nullable=False),
    sa.Column('threshold', sa.Float(), nullable=False),
    sa.Column('action_taken', sa.String(length=50), nullable=False),
    sa.Column('details', sa.Text(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('model_training_logs',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('model_version', sa.String(length=100), nullable=False),
    sa.Column('trigger_reason', sa.String(length=50), nullable=False),
    sa.Column('training_samples', sa.Integer(), nullable=False),
    sa.Column('accuracy_before', sa.Float(), nullable=True),
    sa.Column('accuracy_after', sa.Float(), nullable=False),
    sa.Column('training_duration_seconds', sa.Float(), nullable=False),
    sa.Column('mlflow_run_id', sa.String(length=100), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('monitoring_metrics',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('metric_name', sa.String(length=100), nullable=False),
    sa.Column('metric_value', sa.Float(), nullable=False),
    sa.Column('metric_type', sa.String(length=20), nullable=False),
    sa.Column('labels', sa.Text(), nullable=True),
    sa.Column('timestamp', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('users',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('username', sa.String(length=50), nullable=False),
    sa.Column('email', sa.String(length=100), nullable=False),
    sa.Column('password_hash', sa.String(length=128), nullable=False),
    sa.Column('salt', sa.String(length=64), nullable=False),
    sa.Column('role', sa.String(length=20), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.Column('last_login', sa.DateTime(), nullable=True),
    sa.Column('login_count', sa.Integer(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('email'),
    sa.UniqueConstraint('username')
    )
    op.create_table('login_sessions',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=True),
    sa.Column('ip_address', sa.String(length=45), nullable=True),
    sa.Column('user_agent', sa.Text(), nullable=True),
    sa.Column('login_time', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.Column('success', sa.Boolean(), nullable=False),
    sa.Column('failure_reason', sa.String(length=200), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('system_logs',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('level', sa.String(length=10), nullable=False),
    sa.Column('component', sa.String(length=50), nullable=False),
    sa.Column('event_type', sa.String(length=50), nullable=False),
    sa.Column('message', sa.Text(), nullable=False),
    sa.Column('details', sa.Text(), nullable=True),
    sa.Column('user_id', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_table('tokens',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('token_hash', sa.String(length=64), nullable=False),
    sa.Column('expires_at', sa.DateTime(), nullable=False),
    sa.Column('is_revoked', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.drop_table('experiments')
    op.drop_index('ix_dataset_generations_generation_id', table_name='dataset_generations')
    op.drop_index('ix_dataset_generations_id', table_name='dataset_generations')
    op.drop_table('dataset_generations')
    op.drop_index('ix_monitoring_events_id', table_name='monitoring_events')
    op.drop_table('monitoring_events')
    op.drop_index('ix_model_versions_id', table_name='model_versions')
    op.drop_index('ix_model_versions_version', table_name='model_versions')
    op.drop_table('model_versions')
    op.drop_index('ix_dataset_samples_generation_id', table_name='dataset_samples')
    op.drop_index('ix_dataset_samples_id', table_name='dataset_samples')
    op.create_foreign_key(None, 'dataset_samples', 'datasets', ['generation_id'], ['generation_id'])
    op.drop_column('dataset_samples', 'created_at')
    op.alter_column('datasets', 'generation_id',
               existing_type=sa.INTEGER(),
               nullable=False,
               autoincrement=True)
    op.alter_column('datasets', 'samples_count',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('datasets', 'hour_generated',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('datasets', 'created_at',
               existing_type=sa.TIMESTAMP(),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('(CURRENT_TIMESTAMP)'))
    op.drop_column('datasets', 'id')
    op.alter_column('models', 'id',
               existing_type=sa.INTEGER(),
               nullable=False,
               autoincrement=True)
    op.alter_column('models', 'version',
               existing_type=sa.TEXT(),
               type_=sa.String(length=100),
               nullable=False)
    op.alter_column('models', 'accuracy',
               existing_type=sa.REAL(),
               type_=sa.Float(),
               nullable=False)
    op.alter_column('models', 'training_samples',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('models', 'created_at',
               existing_type=sa.TIMESTAMP(),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('(CURRENT_TIMESTAMP)'))
    op.add_column('prediction_logs', sa.Column('user_id', sa.Integer(), nullable=True))
    op.alter_column('prediction_logs', 'confidence',
               existing_type=sa.FLOAT(),
               nullable=False)
    op.drop_index('ix_prediction_logs_id', table_name='prediction_logs')
    op.create_foreign_key(None, 'prediction_logs', 'users', ['user_id'], ['id'])
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'prediction_logs', type_='foreignkey')
    op.create_index('ix_prediction_logs_id', 'prediction_logs', ['id'], unique=False)
    op.alter_column('prediction_logs', 'confidence',
               existing_type=sa.FLOAT(),
               nullable=True)
    op.drop_column('prediction_logs', 'user_id')
    op.alter_column('models', 'created_at',
               existing_type=sa.DateTime(),
               type_=sa.TIMESTAMP(),
               existing_nullable=True,
               existing_server_default=sa.text('(CURRENT_TIMESTAMP)'))
    op.alter_column('models', 'training_samples',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('models', 'accuracy',
               existing_type=sa.Float(),
               type_=sa.REAL(),
               nullable=True)
    op.alter_column('models', 'version',
               existing_type=sa.String(length=100),
               type_=sa.TEXT(),
               nullable=True)
    op.alter_column('models', 'id',
               existing_type=sa.INTEGER(),
               nullable=True,
               autoincrement=True)
    op.add_column('datasets', sa.Column('id', sa.INTEGER(), nullable=True))
    op.alter_column('datasets', 'created_at',
               existing_type=sa.DateTime(),
               type_=sa.TIMESTAMP(),
               existing_nullable=True,
               existing_server_default=sa.text('(CURRENT_TIMESTAMP)'))
    op.alter_column('datasets', 'hour_generated',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('datasets', 'samples_count',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('datasets', 'generation_id',
               existing_type=sa.INTEGER(),
               nullable=True,
               autoincrement=True)
    op.add_column('dataset_samples', sa.Column('created_at', sa.DATETIME(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True))
    op.drop_constraint(None, 'dataset_samples', type_='foreignkey')
    op.create_index('ix_dataset_samples_id', 'dataset_samples', ['id'], unique=False)
    op.create_index('ix_dataset_samples_generation_id', 'dataset_samples', ['generation_id'], unique=False)
    op.create_table('model_versions',
    sa.Column('id', sa.INTEGER(), nullable=False),
    sa.Column('version', sa.VARCHAR(length=100), nullable=False),
    sa.Column('model_type', sa.VARCHAR(length=50), nullable=False),
    sa.Column('hyperparameters', sa.TEXT(), nullable=True),
    sa.Column('training_samples', sa.INTEGER(), nullable=False),
    sa.Column('accuracy', sa.FLOAT(), nullable=True),
    sa.Column('precision_score', sa.FLOAT(), nullable=True),
    sa.Column('recall_score', sa.FLOAT(), nullable=True),
    sa.Column('f1_score', sa.FLOAT(), nullable=True),
    sa.Column('file_path', sa.VARCHAR(length=255), nullable=True),
    sa.Column('mlflow_run_id', sa.VARCHAR(length=100), nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), nullable=True),
    sa.Column('created_at', sa.DATETIME(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.Column('updated_at', sa.DATETIME(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_model_versions_version', 'model_versions', ['version'], unique=1)
    op.create_index('ix_model_versions_id', 'model_versions', ['id'], unique=False)
    op.create_table('monitoring_events',
    sa.Column('id', sa.INTEGER(), nullable=False),
    sa.Column('event_type', sa.VARCHAR(length=50), nullable=False),
    sa.Column('status', sa.VARCHAR(length=20), nullable=False),
    sa.Column('message', sa.TEXT(), nullable=True),
    sa.Column('details', sa.TEXT(), nullable=True),
    sa.Column('source', sa.VARCHAR(length=50), nullable=True),
    sa.Column('notification_sent', sa.BOOLEAN(), nullable=True),
    sa.Column('created_at', sa.DATETIME(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_monitoring_events_id', 'monitoring_events', ['id'], unique=False)
    op.create_table('dataset_generations',
    sa.Column('id', sa.INTEGER(), nullable=False),
    sa.Column('generation_id', sa.INTEGER(), nullable=False),
    sa.Column('samples_count', sa.INTEGER(), nullable=False),
    sa.Column('feature1_mean', sa.FLOAT(), nullable=True),
    sa.Column('feature1_std', sa.FLOAT(), nullable=True),
    sa.Column('feature2_mean', sa.FLOAT(), nullable=True),
    sa.Column('feature2_std', sa.FLOAT(), nullable=True),
    sa.Column('target_distribution', sa.VARCHAR(length=100), nullable=True),
    sa.Column('time_modification_applied', sa.BOOLEAN(), nullable=True),
    sa.Column('hour_generated', sa.INTEGER(), nullable=True),
    sa.Column('created_at', sa.DATETIME(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.Column('updated_at', sa.DATETIME(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('ix_dataset_generations_id', 'dataset_generations', ['id'], unique=False)
    op.create_index('ix_dataset_generations_generation_id', 'dataset_generations', ['generation_id'], unique=1)
    op.create_table('experiments',
    sa.Column('id', sa.INTEGER(), nullable=True),
    sa.Column('experiment_id', sa.TEXT(), nullable=True),
    sa.Column('run_id', sa.TEXT(), nullable=True),
    sa.Column('model_version', sa.TEXT(), nullable=True),
    sa.Column('accuracy', sa.REAL(), nullable=True),
    sa.Column('parameters', sa.TEXT(), nullable=True),
    sa.Column('created_at', sa.TIMESTAMP(), server_default=sa.text('(CURRENT_TIMESTAMP)'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.drop_table('tokens')
    op.drop_table('system_logs')
    op.drop_table('login_sessions')
    op.drop_table('users')
    op.drop_table('monitoring_metrics')
    op.drop_table('model_training_logs')
    op.drop_table('drift_detections')
    # ### end Alembic commands ###
